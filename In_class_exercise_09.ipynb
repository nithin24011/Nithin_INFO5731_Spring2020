{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_09.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RFs6P4jT4Sq"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 4/16/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChRTK4ImT4Sy"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL6d9EagT4Sz"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "#importing libraries needed\n",
        "\n",
        "import pandas as pd \n",
        "import re \n",
        "import nltk \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9LwBBNtXIyT"
      },
      "source": [
        "#Loading Train and Test data\n",
        "\n",
        "my_data_train=pd.read_fwf(\"/content/stsa-train.txt\", header=None)\n",
        "my_data_train= pd.DataFrame(my_data_train)\n",
        "my_data_test=pd.read_fwf(\"/content/stsa-test.txt\", header=None)\n",
        "my_data_test= pd.DataFrame(my_data_test)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8ezPMyjXepD"
      },
      "source": [
        "#Now splitting my_data_train into training and validation data\n",
        "\n",
        "del my_data_train[2]\n",
        "my_data_train = my_data_train.rename(columns={0: \"Review\", 1: \"Text\"})\n",
        "del my_data_test[2]\n",
        "del my_data_test[3]\n",
        "my_data_test = my_data_test.rename(columns={0: \"Review\", 1: \"Text\"})\n",
        "x_train, x_validate, y_train, y_validate = sklearn.model_selection.train_test_split(my_data_train['Text'], my_data_train['Review'], train_size=0.8, test_size=0.2)\n",
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-KSEt1pXnZm"
      },
      "source": [
        "# Defining K-fold\n",
        "\n",
        "my_kf = KFold(n_splits=10)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs-q6WPYXxZz"
      },
      "source": [
        "#MultinominalNB\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    MNB_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = MNB_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6HVqk2bXxXM",
        "outputId": "59f95d8d-1559-44e7-d693-3b4f6865999d"
      },
      "source": [
        "#Evaluation\n",
        "\n",
        "my_final = MNB_algorithm.predict(my_data_test['Text'])\n",
        "print('Accuracy of MultinomialNB :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of MultinomialNB :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print('Precision of MultinomialNB :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of MultinomialNB :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of MultinomialNB : 80.83470620538165\n",
            "Recall of MultinomialNB : 87.8987898789879\n",
            "Precision of MultinomialNB : 80.83470620538165\n",
            "F1-score of MultinomialNB : 80.742508329129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rjes-fDXxVG"
      },
      "source": [
        "#SVM\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', LinearSVC())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    SVM_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = SVM_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSRY5qazX6-Z",
        "outputId": "6c75bbca-f54f-4530-ca72-1718b6392240"
      },
      "source": [
        "#Evaluation\n",
        "my_final = SVM_algorithm.predict(my_data_test['Text'])\n",
        "print(' Accuracy of SVM :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of SVM :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print(' Precision of SVM :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of SVM :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy of SVM : 79.40691927512356\n",
            "Recall of SVM : 81.95819581958196\n",
            " Precision of SVM : 79.40691927512356\n",
            "F1-score of SVM : 79.39488941961706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79r2o-cYXxSS"
      },
      "source": [
        "#KNN\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', KNeighborsClassifier())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    KNN_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = KNN_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOulhBdZXxP6",
        "outputId": "ce36738e-8479-41ea-ea85-8ebcb2dff42c"
      },
      "source": [
        "#Evaluation of KNN\n",
        "my_final = KNN_algorithm.predict(my_data_test['Text'])\n",
        "print(' Accuracy of KNN :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of KNN :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print(' Precision of KNN :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of KNN :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy of KNN : 73.47611202635915\n",
            "Recall of KNN : 77.55775577557755\n",
            " Precision of KNN : 73.47611202635915\n",
            "F1-score of KNN : 73.4345820432595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXmSLfsEXxNT"
      },
      "source": [
        "#Decision Tree\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', tree.DecisionTreeClassifier())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    DT_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = DT_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb_m8K0YXxKi",
        "outputId": "d6ca4fef-8e4c-4e48-ae76-ce33c61f28b6"
      },
      "source": [
        "#Evaluation\n",
        "my_final = DT_algorithm.predict(my_data_test['Text'])\n",
        "print(' Accuracy of Decision Tree :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of Decision Tree :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print(' Precision of Decision Tree :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of Decision Tree :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy of Decision Tree : 60.73585941790225\n",
            "Recall of Decision Tree : 65.8965896589659\n",
            " Precision of Decision Tree : 60.73585941790225\n",
            "F1-score of Decision Tree : 60.63538354511475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_Dq4GvRXxBz"
      },
      "source": [
        "#Random Forest:\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', RandomForestClassifier(n_estimators=100))])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    RF_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = RF_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcjitZM_YSAN",
        "outputId": "38cd7495-2cf7-4ae2-dc5f-1c006be3a2e4"
      },
      "source": [
        "#Evaluation\n",
        "my_final = RF_algorithm.predict(my_data_test['Text'])\n",
        "print(' Accuracy of Random Forest :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of Random Forest :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print(' Precision of Random Forest :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of Random Forest :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy of Random Forest : 72.32289950576606\n",
            "Recall of Random Forest : 76.56765676567657\n",
            " Precision of Random Forest : 72.32289950576606\n",
            "F1-score of Random Forest : 72.27587106877202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4a8-h64YiYk",
        "outputId": "2750965e-a8bb-481f-bd98-12744969de3f"
      },
      "source": [
        "#XGBoost:\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', GradientBoostingClassifier(n_estimators=20,verbose=2))])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    \n",
        "    XGB_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = XGB_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3759            0.59s\n",
            "         2           1.3684            0.56s\n",
            "         3           1.3621            0.52s\n",
            "         4           1.3562            0.49s\n",
            "         5           1.3509            0.45s\n",
            "         6           1.3458            0.43s\n",
            "         7           1.3410            0.40s\n",
            "         8           1.3368            0.37s\n",
            "         9           1.3324            0.34s\n",
            "        10           1.3284            0.31s\n",
            "        11           1.3244            0.28s\n",
            "        12           1.3212            0.25s\n",
            "        13           1.3178            0.21s\n",
            "        14           1.3140            0.18s\n",
            "        15           1.3106            0.16s\n",
            "        16           1.3073            0.12s\n",
            "        17           1.3047            0.09s\n",
            "        18           1.3008            0.06s\n",
            "        19           1.2976            0.03s\n",
            "        20           1.2943            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3765            0.56s\n",
            "         2           1.3696            0.53s\n",
            "         3           1.3636            0.49s\n",
            "         4           1.3582            0.47s\n",
            "         5           1.3528            0.44s\n",
            "         6           1.3479            0.41s\n",
            "         7           1.3428            0.41s\n",
            "         8           1.3388            0.38s\n",
            "         9           1.3345            0.35s\n",
            "        10           1.3311            0.31s\n",
            "        11           1.3264            0.28s\n",
            "        12           1.3217            0.25s\n",
            "        13           1.3187            0.22s\n",
            "        14           1.3151            0.19s\n",
            "        15           1.3115            0.16s\n",
            "        16           1.3084            0.13s\n",
            "        17           1.3053            0.09s\n",
            "        18           1.3022            0.06s\n",
            "        19           1.2989            0.03s\n",
            "        20           1.2958            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3757            0.58s\n",
            "         2           1.3685            0.54s\n",
            "         3           1.3619            0.51s\n",
            "         4           1.3562            0.51s\n",
            "         5           1.3512            0.47s\n",
            "         6           1.3458            0.44s\n",
            "         7           1.3408            0.42s\n",
            "         8           1.3363            0.38s\n",
            "         9           1.3319            0.35s\n",
            "        10           1.3277            0.32s\n",
            "        11           1.3236            0.29s\n",
            "        12           1.3198            0.26s\n",
            "        13           1.3163            0.22s\n",
            "        14           1.3131            0.19s\n",
            "        15           1.3087            0.16s\n",
            "        16           1.3049            0.13s\n",
            "        17           1.3020            0.10s\n",
            "        18           1.2985            0.06s\n",
            "        19           1.2955            0.03s\n",
            "        20           1.2924            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3763            0.59s\n",
            "         2           1.3687            0.54s\n",
            "         3           1.3625            0.50s\n",
            "         4           1.3565            0.47s\n",
            "         5           1.3512            0.45s\n",
            "         6           1.3464            0.42s\n",
            "         7           1.3417            0.39s\n",
            "         8           1.3373            0.36s\n",
            "         9           1.3333            0.33s\n",
            "        10           1.3292            0.30s\n",
            "        11           1.3249            0.27s\n",
            "        12           1.3220            0.24s\n",
            "        13           1.3181            0.21s\n",
            "        14           1.3148            0.18s\n",
            "        15           1.3114            0.15s\n",
            "        16           1.3075            0.12s\n",
            "        17           1.3042            0.09s\n",
            "        18           1.3014            0.06s\n",
            "        19           1.2992            0.03s\n",
            "        20           1.2961            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3759            0.66s\n",
            "         2           1.3683            0.67s\n",
            "         3           1.3618            0.61s\n",
            "         4           1.3560            0.55s\n",
            "         5           1.3505            0.50s\n",
            "         6           1.3460            0.46s\n",
            "         7           1.3410            0.42s\n",
            "         8           1.3370            0.39s\n",
            "         9           1.3323            0.35s\n",
            "        10           1.3283            0.32s\n",
            "        11           1.3243            0.29s\n",
            "        12           1.3207            0.25s\n",
            "        13           1.3170            0.22s\n",
            "        14           1.3140            0.19s\n",
            "        15           1.3105            0.16s\n",
            "        16           1.3072            0.12s\n",
            "        17           1.3046            0.09s\n",
            "        18           1.3016            0.06s\n",
            "        19           1.2982            0.03s\n",
            "        20           1.2958            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3763            0.57s\n",
            "         2           1.3696            0.53s\n",
            "         3           1.3640            0.50s\n",
            "         4           1.3588            0.47s\n",
            "         5           1.3542            0.44s\n",
            "         6           1.3489            0.42s\n",
            "         7           1.3443            0.40s\n",
            "         8           1.3405            0.37s\n",
            "         9           1.3360            0.34s\n",
            "        10           1.3320            0.30s\n",
            "        11           1.3283            0.28s\n",
            "        12           1.3251            0.25s\n",
            "        13           1.3214            0.22s\n",
            "        14           1.3181            0.19s\n",
            "        15           1.3146            0.15s\n",
            "        16           1.3104            0.12s\n",
            "        17           1.3074            0.09s\n",
            "        18           1.3042            0.06s\n",
            "        19           1.3008            0.03s\n",
            "        20           1.2982            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3755            0.62s\n",
            "         2           1.3679            0.57s\n",
            "         3           1.3613            0.54s\n",
            "         4           1.3556            0.52s\n",
            "         5           1.3504            0.48s\n",
            "         6           1.3453            0.44s\n",
            "         7           1.3409            0.41s\n",
            "         8           1.3368            0.38s\n",
            "         9           1.3327            0.34s\n",
            "        10           1.3284            0.31s\n",
            "        11           1.3245            0.28s\n",
            "        12           1.3209            0.25s\n",
            "        13           1.3175            0.22s\n",
            "        14           1.3145            0.19s\n",
            "        15           1.3121            0.16s\n",
            "        16           1.3086            0.12s\n",
            "        17           1.3049            0.09s\n",
            "        18           1.3019            0.06s\n",
            "        19           1.2987            0.03s\n",
            "        20           1.2958            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3759            0.61s\n",
            "         2           1.3684            0.56s\n",
            "         3           1.3619            0.52s\n",
            "         4           1.3561            0.48s\n",
            "         5           1.3511            0.45s\n",
            "         6           1.3464            0.42s\n",
            "         7           1.3421            0.39s\n",
            "         8           1.3382            0.36s\n",
            "         9           1.3339            0.33s\n",
            "        10           1.3298            0.30s\n",
            "        11           1.3265            0.27s\n",
            "        12           1.3226            0.24s\n",
            "        13           1.3189            0.21s\n",
            "        14           1.3145            0.18s\n",
            "        15           1.3114            0.15s\n",
            "        16           1.3082            0.12s\n",
            "        17           1.3054            0.09s\n",
            "        18           1.3025            0.06s\n",
            "        19           1.2999            0.03s\n",
            "        20           1.2969            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3756            0.57s\n",
            "         2           1.3678            0.53s\n",
            "         3           1.3613            0.50s\n",
            "         4           1.3554            0.47s\n",
            "         5           1.3502            0.45s\n",
            "         6           1.3453            0.43s\n",
            "         7           1.3408            0.41s\n",
            "         8           1.3360            0.38s\n",
            "         9           1.3318            0.34s\n",
            "        10           1.3280            0.31s\n",
            "        11           1.3242            0.28s\n",
            "        12           1.3209            0.24s\n",
            "        13           1.3180            0.21s\n",
            "        14           1.3143            0.18s\n",
            "        15           1.3106            0.15s\n",
            "        16           1.3075            0.12s\n",
            "        17           1.3045            0.09s\n",
            "        18           1.3016            0.06s\n",
            "        19           1.2986            0.03s\n",
            "        20           1.2960            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3759            0.61s\n",
            "         2           1.3686            0.61s\n",
            "         3           1.3619            0.56s\n",
            "         4           1.3563            0.51s\n",
            "         5           1.3510            0.47s\n",
            "         6           1.3463            0.44s\n",
            "         7           1.3417            0.41s\n",
            "         8           1.3373            0.38s\n",
            "         9           1.3333            0.34s\n",
            "        10           1.3289            0.31s\n",
            "        11           1.3259            0.28s\n",
            "        12           1.3216            0.25s\n",
            "        13           1.3176            0.22s\n",
            "        14           1.3143            0.19s\n",
            "        15           1.3116            0.16s\n",
            "        16           1.3084            0.12s\n",
            "        17           1.3053            0.09s\n",
            "        18           1.3028            0.06s\n",
            "        19           1.2997            0.03s\n",
            "        20           1.2967            0.00s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDAJMLacYiR8",
        "outputId": "1e5d3744-4cc3-4c45-95a2-6d38232254cc"
      },
      "source": [
        "#Evaluation\n",
        "my_final = XGB_algorithm.predict(my_data_test['Text'])\n",
        "print(' Accuracy of XG Boost :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of XG Boost :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print(' Precision of XG Boost :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of XG Boost :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy of XG Boost : 59.30807248764415\n",
            "Recall of XG Boost : 87.56875687568757\n",
            " Precision of XG Boost : 59.30807248764415\n",
            "F1-score of XG Boost : 55.81511098769867\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_08-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nithin24011/Nithin_INFO5731_Spring2020/blob/main/In_class_exercise_08_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5z80pMEpeQG"
      },
      "source": [
        "# **The eighth in-class-exercise (20 points in total, 3/30/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMfWVe3BpeQI"
      },
      "source": [
        "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXRIGM47peQJ"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gyB2FdapeQJ",
        "outputId": "157a80c7-70a4-483e-8a13-579fc2ed0fd9"
      },
      "source": [
        "# Write your code here\n",
        "!pip install TextBlob"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: TextBlob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from TextBlob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->TextBlob) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "kad5kJFppj1x",
        "outputId": "ebe9a8f3-7499-4ec9-9923-3a82afd5b534"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/joker_data1.csv\")\n",
        "data.head(10)\n",
        "main_df=data[[\"review_content\"]]\n",
        "main_df.head(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I was a person that saw all the hype and claim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Every once in a while a movie comes, that trul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is a movie that only those who have felt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Truly a masterpiece, The Best Hollywood film o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Most of the time movies are anticipated like t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Joaquin Phoenix gives a tour de force performa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Let me start off by saying if Joaquin Phoneix ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I get why some people hate this . It's because...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I have seen Joker yesterday at Venice an early...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>It's sad that Joaquin missed Oscar for 'The gl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      review_content\n",
              "0  I was a person that saw all the hype and claim...\n",
              "1  Every once in a while a movie comes, that trul...\n",
              "2  This is a movie that only those who have felt ...\n",
              "3  Truly a masterpiece, The Best Hollywood film o...\n",
              "4  Most of the time movies are anticipated like t...\n",
              "5  Joaquin Phoenix gives a tour de force performa...\n",
              "6  Let me start off by saying if Joaquin Phoneix ...\n",
              "7  I get why some people hate this . It's because...\n",
              "8  I have seen Joker yesterday at Venice an early...\n",
              "9  It's sad that Joaquin missed Oscar for 'The gl..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "lVJ3KMA-pwjX",
        "outputId": "f5ce5540-4a72-48f9-cd06-2a40179e8f43"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "#remove stop words \n",
        "from nltk.corpus import stopwords\n",
        "stopwords = list(stopwords.words('english'))\n",
        "\n",
        "#find the occurance of each word from the list\n",
        "main_df[\"Tokens\"] = main_df[\"review_content\"].apply(lambda x : nltk.word_tokenize(str(x)))\n",
        "main_df.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_content</th>\n",
              "      <th>Tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I was a person that saw all the hype and claim...</td>\n",
              "      <td>[I, was, a, person, that, saw, all, the, hype,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Every once in a while a movie comes, that trul...</td>\n",
              "      <td>[Every, once, in, a, while, a, movie, comes, ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is a movie that only those who have felt ...</td>\n",
              "      <td>[This, is, a, movie, that, only, those, who, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Truly a masterpiece, The Best Hollywood film o...</td>\n",
              "      <td>[Truly, a, masterpiece, ,, The, Best, Hollywoo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Most of the time movies are anticipated like t...</td>\n",
              "      <td>[Most, of, the, time, movies, are, anticipated...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Joaquin Phoenix gives a tour de force performa...</td>\n",
              "      <td>[Joaquin, Phoenix, gives, a, tour, de, force, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Let me start off by saying if Joaquin Phoneix ...</td>\n",
              "      <td>[Let, me, start, off, by, saying, if, Joaquin,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I get why some people hate this . It's because...</td>\n",
              "      <td>[I, get, why, some, people, hate, this, ., It,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I have seen Joker yesterday at Venice an early...</td>\n",
              "      <td>[I, have, seen, Joker, yesterday, at, Venice, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>It's sad that Joaquin missed Oscar for 'The gl...</td>\n",
              "      <td>[It, 's, sad, that, Joaquin, missed, Oscar, fo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      review_content                                             Tokens\n",
              "0  I was a person that saw all the hype and claim...  [I, was, a, person, that, saw, all, the, hype,...\n",
              "1  Every once in a while a movie comes, that trul...  [Every, once, in, a, while, a, movie, comes, ,...\n",
              "2  This is a movie that only those who have felt ...  [This, is, a, movie, that, only, those, who, h...\n",
              "3  Truly a masterpiece, The Best Hollywood film o...  [Truly, a, masterpiece, ,, The, Best, Hollywoo...\n",
              "4  Most of the time movies are anticipated like t...  [Most, of, the, time, movies, are, anticipated...\n",
              "5  Joaquin Phoenix gives a tour de force performa...  [Joaquin, Phoenix, gives, a, tour, de, force, ...\n",
              "6  Let me start off by saying if Joaquin Phoneix ...  [Let, me, start, off, by, saying, if, Joaquin,...\n",
              "7  I get why some people hate this . It's because...  [I, get, why, some, people, hate, this, ., It,...\n",
              "8  I have seen Joker yesterday at Venice an early...  [I, have, seen, Joker, yesterday, at, Venice, ...\n",
              "9  It's sad that Joaquin missed Oscar for 'The gl...  [It, 's, sad, that, Joaquin, missed, Oscar, fo..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVdDWAAGp4Zp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "def compute_values(ip):\n",
        "  res1 =pd.value_counts(ip)\n",
        "  if(len(res1)==0 ):\n",
        "    res1 = [0]\n",
        "  return res1\n",
        "\n",
        "#calculate the occurance of each word in the sentence\n",
        "df1 = main_df[\"Tokens\"].apply(lambda x : compute_values(x))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDjktqzUp9Kj"
      },
      "source": [
        "df1 = df1.fillna(0)\n",
        "final_df = pd.DataFrame(df1.columns, columns=[\"Tokens\"])\n",
        "res = pd.DataFrame(df1.T.sum(axis=1),columns = [\"value\"]).values.tolist()\n",
        "final_df[\"value_of_tf\"] = pd.DataFrame(res)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "WvecSNz-qGpa",
        "outputId": "02a83ee6-74f8-499b-ae5c-d6a361f055dd"
      },
      "source": [
        "final_df.head(10)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tokens</th>\n",
              "      <th>value_of_tf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>and</td>\n",
              "      <td>494.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>.</td>\n",
              "      <td>726.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the</td>\n",
              "      <td>719.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a</td>\n",
              "      <td>484.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>of</td>\n",
              "      <td>377.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>is</td>\n",
              "      <td>347.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>was</td>\n",
              "      <td>173.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>to</td>\n",
              "      <td>381.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>that</td>\n",
              "      <td>214.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>,</td>\n",
              "      <td>674.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Tokens  value_of_tf\n",
              "0    and        494.0\n",
              "1      .        726.0\n",
              "2    the        719.0\n",
              "3      a        484.0\n",
              "4     of        377.0\n",
              "5     is        347.0\n",
              "6    was        173.0\n",
              "7     to        381.0\n",
              "8   that        214.0\n",
              "9      ,        674.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "D7hZ_gD5qbIw",
        "outputId": "37168176-17a6-4c7c-9db6-cdd115acacf6"
      },
      "source": [
        "from textblob  import TextBlob\n",
        "#find the polarity \n",
        "final_df[\"Polarity\"] = final_df['Tokens'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "#filter the influencing variables \n",
        "iv = final_df[\"Polarity\"] != 0\n",
        "iv_filter = final_df[iv]\n",
        "iv_filter.head(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tokens</th>\n",
              "      <th>value_of_tf</th>\n",
              "      <th>Polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>best</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>pretentious</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>bleak</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>rare</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>brilliant</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>extremely</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>proud</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>impeccable</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>incredibly</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>magnificently</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Tokens  value_of_tf  Polarity\n",
              "19           best         27.0     1.000\n",
              "38    pretentious          3.0    -0.300\n",
              "43          bleak          2.0    -1.000\n",
              "45           rare          1.0     0.300\n",
              "47      brilliant          9.0     0.900\n",
              "48      extremely          3.0    -0.125\n",
              "55          proud          1.0     0.800\n",
              "64     impeccable          1.0     0.750\n",
              "67     incredibly          3.0     0.900\n",
              "68  magnificently          1.0     1.000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "63wMy3fKqzEx",
        "outputId": "24a58836-e686-43df-f1c9-d5f47f282fbf"
      },
      "source": [
        "#ranks based on the occurance \n",
        "result = iv_filter.sort_values(by = [\"value_of_tf\"],ascending = False).reset_index()\n",
        "result[\"Rank\"] = pd.DataFrame(range(1,242))\n",
        "result.head(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>value_of_tf</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>436</td>\n",
              "      <td>good</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.700</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>282</td>\n",
              "      <td>more</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>87</td>\n",
              "      <td>very</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.200</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>328</td>\n",
              "      <td>many</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>250</td>\n",
              "      <td>much</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.200</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>531</td>\n",
              "      <td>really</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.200</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>19</td>\n",
              "      <td>best</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>207</td>\n",
              "      <td>other</td>\n",
              "      <td>26.0</td>\n",
              "      <td>-0.125</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>293</td>\n",
              "      <td>bad</td>\n",
              "      <td>24.0</td>\n",
              "      <td>-0.700</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>434</td>\n",
              "      <td>most</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  Tokens  value_of_tf  Polarity  Rank\n",
              "0    436    good         54.0     0.700   1.0\n",
              "1    282    more         52.0     0.500   2.0\n",
              "2     87    very         40.0     0.200   3.0\n",
              "3    328    many         33.0     0.500   4.0\n",
              "4    250    much         32.0     0.200   5.0\n",
              "5    531  really         29.0     0.200   6.0\n",
              "6     19    best         27.0     1.000   7.0\n",
              "7    207   other         26.0    -0.125   8.0\n",
              "8    293     bad         24.0    -0.700   9.0\n",
              "9    434    most         24.0     0.500  10.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CTDKFH1peQK"
      },
      "source": [
        "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers. \n",
        "\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "Pc_zUJbqpeQK",
        "outputId": "f623457c-d7f8-486f-88a3-a4ca9f13208e"
      },
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "df=pd.read_csv(\"/content/joker_data1.csv\",usecols=[\"review_content\",\"Sentiment\"])\n",
        "df=df.dropna().reset_index()\n",
        "df"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>review_content</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>I was a person that saw all the hype and claim...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Every once in a while a movie comes, that trul...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>This is a movie that only those who have felt ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Truly a masterpiece, The Best Hollywood film o...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Most of the time movies are anticipated like t...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>Dark, depressing and unsettling film with a ha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>I just didn't get the hype about this movie. A...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>Story was just really unconvincing. Nobody rea...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>JOKER is a gift to the audiences. I felt as a ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>There is doing an homage and then there is bor...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    index                                     review_content Sentiment\n",
              "0       0  I was a person that saw all the hype and claim...  Positive\n",
              "1       1  Every once in a while a movie comes, that trul...  Positive\n",
              "2       2  This is a movie that only those who have felt ...  Positive\n",
              "3       3  Truly a masterpiece, The Best Hollywood film o...  Positive\n",
              "4       4  Most of the time movies are anticipated like t...  Negative\n",
              "..    ...                                                ...       ...\n",
              "95     95  Dark, depressing and unsettling film with a ha...  Positive\n",
              "96     96  I just didn't get the hype about this movie. A...  Negative\n",
              "97     97  Story was just really unconvincing. Nobody rea...  Negative\n",
              "98     98  JOKER is a gift to the audiences. I felt as a ...  Positive\n",
              "99     99  There is doing an homage and then there is bor...  Negative\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9XRiKtwuPnN"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "textblob_data = pd.read_csv(\"/content/joker_data1.csv\")\n",
        "textblob_data['polarity'] = textblob_data['review_content'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "textblob_data['predicted sentiment'] = pd.cut(textblob_data['polarity'], bins=4, labels=[1, 2, 3, 4])\n",
        "#Defining sentiment\n",
        "def sentiment(x):\n",
        "    if x in [1, 2]:\n",
        "        return 'Negative'\n",
        "    if x == 3:\n",
        "        return 'Neutral'\n",
        "    if x == 4:\n",
        "        return 'Positive'\n",
        "textblob_data['predicted sentiment'] = textblob_data['predicted sentiment'].apply(lambda x: sentiment(x))\n",
        "print(textblob_data[['documentid', 'sentiment', 'predicted sentiment']].head(5))\n",
        "textblob_accuracy = accuracy_score(textblob_data['sentiment'], textblob_data['predicted sentiment'])*100\n",
        "textblob_f1 = f1_score(textblob_data['sentiment'], textblob_data['predicted sentiment'], average='macro')\n",
        "print(' f1-score of the TextBlob:', textblob_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjw6qbovu3-b"
      },
      "source": [
        "```\n",
        "\n",
        "   documentid sentiment predicted sentiment\n",
        "0           0  positive             Neutral\n",
        "1           1  positive             Neutral\n",
        "2           2  positive             Neutral\n",
        "3           3  positive             Neutral\n",
        "4           4  positive             Neutral\n",
        " f1-score of the TextBlob: 0.0\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGhdSciuu-rd"
      },
      "source": [
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "vader = SentimentIntensityAnalyzer()\n",
        "\n",
        "myvader_data = pd.read_csv(\"/content/joker_data1.csv\")\n",
        "myvader_data['polarity'] = textblob_data['review_content'].apply(lambda x: vader.polarity_scores(x)['compound'])\n",
        "myvader_data['predicted sentiment'] = pd.cut(myvader_data['polarity'], bins=4, labels=[1, 2, 3, 4])\n",
        "myvader_data['predicted sentiment'] = myvader_data['predicted sentiment'].apply(lambda x: sentiment(x))\n",
        "print(myvader_data[['documentid', 'sentiment', 'predicted sentiment']].head(5))\n",
        "vader_accuracy = accuracy_score(myvader_data['sentiment'], myvader_data['predicted sentiment'])*100\n",
        "vader_f1 = f1_score(myvader_data['sentiment'], myvader_data['predicted sentiment'], average='macro')\n",
        "print(' f1-score of the VADER sentiment identification :', vader_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3WOf9tQvTcO"
      },
      "source": [
        "```\n",
        "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
        "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
        "   documentid sentiment predicted sentiment\n",
        "0           0  positive             Neutral\n",
        "1           1  positive            Positive\n",
        "2           2  positive            Positive\n",
        "3           3  positive            Positive\n",
        "4           4  positive            Negative\n",
        " f1-score of the VADER sentiment identification : 0.0\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2o4pxanvX1M"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "mysvm = pd.read_csv(\"/content/joker_data1.csv\")\n",
        "train, test = sklearn.model_selection.train_test_split(mysvm, train_size=0.6, test_size=0.1)\n",
        "mypip = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=100, \n",
        "                                           learning_rate='optimal', tol=None))])\n",
        "\n",
        "svm = mypip.fit(train['review_content'], train['sentiment'])\n",
        "test['predicted sentiment'] = svm.predict(test['review_content'])\n",
        "print(test[['documentid', 'sentiment', 'predicted sentiment']].head(5))\n",
        "\n",
        "mysvm_acc = accuracy_score(test['sentiment'], test['predicted sentiment'])*100\n",
        "mysvm_f1 = f1_score(test['sentiment'], test['predicted sentiment'], average='macro')\n",
        "\n",
        "print('Accuracy of the TFIDF-based SVM:', mysvm_acc)\n",
        "print('f1-score of the TFIDF-based SVM :', mysvm_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nNYBXS7vn5h"
      },
      "source": [
        "```\n",
        "    documentid sentiment predicted sentiment\n",
        "70          70  positive            positive\n",
        "96          96  positive            positive\n",
        "58          58  positive            positive\n",
        "15          15  positive            positive\n",
        "0            0  positive            positive\n",
        "Accuracy of the TFIDF-based SVM: 90.0\n",
        "f1-score of the TFIDF-based SVM : 0.4736842105263158\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-3p4_LVv6yq"
      },
      "source": [
        "Sentiment Analysis can be done by using \n",
        "\n",
        "1.TextBlob\n",
        "\n",
        "2.VADER\n",
        "\n",
        "3.TF-IDF based SVM. \n",
        "\n",
        "**TextBlob**:TextBlob is a popular Python library for processing textual data. It is built on top of NLTK, another popular Natural Language Processing toolbox for Python. \n",
        "TextBlob uses a sentiment lexicon (consisting of predefined words) to assign scores for each word, which are then averaged out to give an overall sentence sentiment score.\n",
        "\n",
        "**VADER**: Valence Aware Dictionary and sEntiment Reasoner is another popular rule-based library for sentiment analysis.\n",
        "Like TextBlob, it uses a sentiment lexicon that contains intensity measures for each word based on human-annotated labels. A key difference however, is that VADER was designed with a focus on social m\n",
        "This means that it puts a lot of emphasis on rules that capture the essence of text typically seen on social media\n",
        "\n",
        "**SVM**:TF-IDF is a numerical statistic that is intended to reflect how important a word is to a text document.\n",
        "Support Vector Machine (SVM) is one of the most frequently used classification algorithms in text categorization.\n",
        "It can deal with linear and non-linear data classification with the help of kernel function\n",
        "\n",
        "The performance of the models can be measured using accuracy score and f1 score. \n",
        "\n",
        "**Analysis**:\n",
        "From my analysis,TF-IDF Based SVM has given the best accuracy and f1 score, with 90% and 0.47 respectively,\n",
        "which means out of the three models i have used for doing sentiment analysis.SVM is the best model for sentiment analysis. \n",
        "VADER and Textblob was not at all goodto identify."
      ]
    }
  ]
}